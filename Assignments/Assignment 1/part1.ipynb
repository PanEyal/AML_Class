{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### <u>Loading the digits datase and preliminary data analysis</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 289,
     "status": "ok",
     "timestamp": 1680867897706,
     "user": {
      "displayName": "koren abitbul",
      "userId": "16610089647311253920"
     },
     "user_tz": -180
    },
    "id": "V69FVQcno0kh"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "digits = load_digits()\n",
    "X, y = digits['data'], digits['target']  # type: np.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ZutI2vUQq8u7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of samples in the dataset is:  1797\n",
      "the dimension (or features) of each data sample is:  64\n",
      "the mean value of the mean fetures values of the dataset is: 4.884\n",
      "the variance is: 36.202\n",
      "the scaling of the data is: integers between 0 and 16\n",
      "heres an example of some data sample:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZoAAAGkCAYAAAAIduO+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAYxUlEQVR4nO3df2zUhf3H8ddJ5VBsz4IU23BARSI/CogtcwWcKNikQaLZxnRBVsdc6CwINiZa/UPcD479sW90YTaUkU7isIRMkGUDbDMpLqYbbWxkaBBWYg+FNZByV5rliO3n+9cuVmzp5+i7Hz7X5yP5RO/4nJ9XDPL0017bgOM4jgAAMHKD1wMAAOmN0AAATBEaAIApQgMAMEVoAACmCA0AwBShAQCYIjQAAFOEBgBgitAAAEylTWhef/115efna8yYMSosLNT777/v9aSrOnLkiFasWKG8vDwFAgHt27fP60mDEolEtGDBAmVmZionJ0ePPvqoTpw44fWsQamurtbcuXOVlZWlrKwsFRcX68CBA17Pci0SiSgQCGjjxo1eT7mqTZs2KRAI9Dluv/12r2cNyueff64nnnhC48eP180336y7775bLS0tXs+6qqlTp17x7zwQCKiiosKTPWkRmt27d2vjxo166aWX9OGHH+q+++5TaWmp2tvbvZ42oO7ubs2bN09bt271eoorjY2NqqioUFNTk+rr6/Xll1+qpKRE3d3dXk+7qkmTJmnLli1qbm5Wc3OzHnzwQT3yyCM6fvy419MG7ejRo6qpqdHcuXO9njJos2fP1tmzZ5PHsWPHvJ50VZ2dnVq0aJFuvPFGHThwQB9//LF+85vf6NZbb/V62lUdPXq0z7/v+vp6SdLKlSu9GeSkgW9961tOeXl5n+dmzJjhvPDCCx4tck+Ss3fvXq9npKSjo8OR5DQ2Nno9JSXZ2dnO73//e69nDEpXV5czffp0p76+3rn//vudDRs2eD3pql5++WVn3rx5Xs9w7fnnn3cWL17s9YwhsWHDBmfatGlOb2+vJ9f3/R3N5cuX1dLSopKSkj7Pl5SU6IMPPvBo1cgSi8UkSePGjfN4iTs9PT2qq6tTd3e3iouLvZ4zKBUVFVq+fLmWLVvm9RRXTp48qby8POXn5+vxxx9XW1ub15Ouav/+/SoqKtLKlSuVk5Oj+fPna/v27V7Pcu3y5ct68803tWbNGgUCAU82+D4058+fV09PjyZOnNjn+YkTJ+rcuXMerRo5HMdRZWWlFi9erIKCAq/nDMqxY8d0yy23KBgMqry8XHv37tWsWbO8nnVVdXV1amlpUSQS8XqKK/fee6927typQ4cOafv27Tp37pwWLlyoCxcueD1tQG1tbaqurtb06dN16NAhlZeX65lnntHOnTu9nubKvn37dPHiRT355JOebcjw7MpD7OuldhzHs3qPJOvWrdNHH32kv//9715PGbS77rpLra2tunjxov70pz+prKxMjY2N13VsotGoNmzYoHfffVdjxozxeo4rpaWlyb+fM2eOiouLNW3aNL3xxhuqrKz0cNnAent7VVRUpM2bN0uS5s+fr+PHj6u6ulo/+tGPPF43eDt27FBpaany8vI82+D7O5rbbrtNo0aNuuLupaOj44q7HAyt9evXa//+/Xrvvfc0adIkr+cM2ujRo3XnnXeqqKhIkUhE8+bN02uvveb1rAG1tLSoo6NDhYWFysjIUEZGhhobG/Xb3/5WGRkZ6unp8XrioI0dO1Zz5szRyZMnvZ4yoNzc3Cv+52PmzJnX/ZuMvuqzzz5TQ0ODnnrqKU93+D40o0ePVmFhYfJdFf9TX1+vhQsXerQqvTmOo3Xr1untt9/W3/72N+Xn53s96Zo4jqNEIuH1jAEtXbpUx44dU2tra/IoKirSqlWr1NraqlGjRnk9cdASiYQ++eQT5ebmej1lQIsWLbribfuffvqppkyZ4tEi92pra5WTk6Ply5d7uiMtPnRWWVmp1atXq6ioSMXFxaqpqVF7e7vKy8u9njagS5cu6dSpU8nHp0+fVmtrq8aNG6fJkyd7uGxgFRUV2rVrl9555x1lZmYm7yZDoZBuuukmj9cN7MUXX1RpaanC4bC6urpUV1enw4cP6+DBg15PG1BmZuYVnwMbO3asxo8ff91/buy5557TihUrNHnyZHV0dOiXv/yl4vG4ysrKvJ42oGeffVYLFy7U5s2b9YMf/ED//Oc/VVNTo5qaGq+nDUpvb69qa2tVVlamjAyP/6j35L1uBn73u985U6ZMcUaPHu3cc889vnir7XvvvedIuuIoKyvzetqAvmmzJKe2ttbraVe1Zs2a5O+TCRMmOEuXLnXeffddr2elxC9vb37sscec3Nxc58Ybb3Ty8vKc7373u87x48e9njUof/7zn52CggInGAw6M2bMcGpqaryeNGiHDh1yJDknTpzweooTcBzH8SZxAICRwPefowEAXN8IDQDAFKEBAJgiNAAAU4QGAGCK0AAATKVVaBKJhDZt2nTdf5X31/l1t+Tf7X7dLfl3u193S/7dfr3sTquvo4nH4wqFQorFYsrKyvJ6zqD5dbfk3+1+3S35d7tfd0v+3X697E6rOxoAwPWH0AAATA37d1rr7e3VF198oczMzCH/eTHxeLzPX/3Cr7sl/273627Jv9v9ulvy73br3Y7jqKurS3l5ebrhhv7vW4b9czRnzpxROBwezksCAAxFo9EBfybVsN/RZGZmDvclIWnjxo1eT0jJK6+84vWElJ0+fdrrCSlZsmSJ1xNSdvHiRa8njEhX+3N92EPDj1f2RjAY9HpCSvz0Dp+v8+v/VPHfKNy62u8Z3gwAADBFaAAApggNAMAUoQEAmCI0AABThAYAYIrQAABMERoAgClCAwAwRWgAAKYIDQDAFKEBAJgiNAAAU4QGAGCK0AAATBEaAICplELz+uuvKz8/X2PGjFFhYaHef//9od4FAEgTrkOze/dubdy4US+99JI+/PBD3XfffSotLVV7e7vFPgCAz7kOzf/93//pJz/5iZ566inNnDlTr776qsLhsKqrqy32AQB8zlVoLl++rJaWFpWUlPR5vqSkRB988ME3viaRSCgej/c5AAAjh6vQnD9/Xj09PZo4cWKf5ydOnKhz585942sikYhCoVDyCIfDqa8FAPhOSm8GCAQCfR47jnPFc/9TVVWlWCyWPKLRaCqXBAD4VIabk2+77TaNGjXqiruXjo6OK+5y/icYDCoYDKa+EADga67uaEaPHq3CwkLV19f3eb6+vl4LFy4c0mEAgPTg6o5GkiorK7V69WoVFRWpuLhYNTU1am9vV3l5ucU+AIDPuQ7NY489pgsXLujnP/+5zp49q4KCAv31r3/VlClTLPYBAHzOdWgk6emnn9bTTz891FsAAGmI73UGADBFaAAApggNAMAUoQEAmCI0AABThAYAYIrQAABMERoAgClCAwAwRWgAAKYIDQDAFKEBAJgiNAAAU4QGAGCK0AAATBEaAICplH7w2Ui1ZcsWryekbOXKlV5PSMnatWu9npCybdu2eT0hJYWFhV5PSFlDQ4PXE/ANuKMBAJgiNAAAU4QGAGCK0AAATBEaAIApQgMAMEVoAACmCA0AwBShAQCYIjQAAFOEBgBgitAAAEwRGgCAKUIDADBFaAAApggNAMAUoQEAmCI0AABThAYAYMp1aI4cOaIVK1YoLy9PgUBA+/btM5gFAEgXrkPT3d2tefPmaevWrRZ7AABpJsPtC0pLS1VaWmqxBQCQhlyHxq1EIqFEIpF8HI/HrS8JALiOmL8ZIBKJKBQKJY9wOGx9SQDAdcQ8NFVVVYrFYskjGo1aXxIAcB0x/9BZMBhUMBi0vgwA4DrF19EAAEy5vqO5dOmSTp06lXx8+vRptba2aty4cZo8efKQjgMA+J/r0DQ3N+uBBx5IPq6srJQklZWV6Q9/+MOQDQMApAfXoVmyZIkcx7HYAgBIQ3yOBgBgitAAAEwRGgCAKUIDADBFaAAApggNAMAUoQEAmCI0AABThAYAYIrQAABMERoAgClCAwAwRWgAAKYIDQDAFKEBAJgiNAAAUwFnmH+KWTweVygUGs5LDpk77rjD6wkp6+zs9HpCSpqbm72eMOJMmzbN6wnwmVgspqysrH5/nTsaAIApQgMAMEVoAACmCA0AwBShAQCYIjQAAFOEBgBgitAAAEwRGgCAKUIDADBFaAAApggNAMAUoQEAmCI0AABThAYAYIrQAABMERoAgClCAwAw5So0kUhECxYsUGZmpnJycvToo4/qxIkTVtsAAGnAVWgaGxtVUVGhpqYm1dfX68svv1RJSYm6u7ut9gEAfC7DzckHDx7s87i2tlY5OTlqaWnRd77znSEdBgBID65C83WxWEySNG7cuH7PSSQSSiQSycfxePxaLgkA8JmU3wzgOI4qKyu1ePFiFRQU9HteJBJRKBRKHuFwONVLAgB8KOXQrFu3Th999JHeeuutAc+rqqpSLBZLHtFoNNVLAgB8KKUPna1fv1779+/XkSNHNGnSpAHPDQaDCgaDKY0DAPifq9A4jqP169dr7969Onz4sPLz8612AQDShKvQVFRUaNeuXXrnnXeUmZmpc+fOSZJCoZBuuukmk4EAAH9z9Tma6upqxWIxLVmyRLm5uclj9+7dVvsAAD7n+kNnAAC4wfc6AwCYIjQAAFOEBgBgitAAAEwRGgCAKUIDADBFaAAApggNAMAUoQEAmCI0AABThAYAYIrQAABMERoAgClCAwAwRWgAAKYIDQDAlKsffDbStbW1eT0hZXfccYfXE1Li192S1NDQ4PWElGRnZ3s9IWWdnZ1eT8A34I4GAGCK0AAATBEaAIApQgMAMEVoAACmCA0AwBShAQCYIjQAAFOEBgBgitAAAEwRGgCAKUIDADBFaAAApggNAMAUoQEAmCI0AABThAYAYIrQAABMERoAgClXoamurtbcuXOVlZWlrKwsFRcX68CBA1bbAABpwFVoJk2apC1btqi5uVnNzc168MEH9cgjj+j48eNW+wAAPpfh5uQVK1b0efyrX/1K1dXVampq0uzZs4d0GAAgPbgKzVf19PRoz5496u7uVnFxcb/nJRIJJRKJ5ON4PJ7qJQEAPuT6zQDHjh3TLbfcomAwqPLycu3du1ezZs3q9/xIJKJQKJQ8wuHwNQ0GAPiL69Dcddddam1tVVNTk372s5+prKxMH3/8cb/nV1VVKRaLJY9oNHpNgwEA/uL6Q2ejR4/WnXfeKUkqKirS0aNH9dprr2nbtm3feH4wGFQwGLy2lQAA37rmr6NxHKfP52AAAPgqV3c0L774okpLSxUOh9XV1aW6ujodPnxYBw8etNoHAPA5V6H5z3/+o9WrV+vs2bMKhUKaO3euDh48qIceeshqHwDA51yFZseOHVY7AABpiu91BgAwRWgAAKYIDQDAFKEBAJgiNAAAU4QGAGCK0AAATBEaAIApQgMAMEVoAACmCA0AwBShAQCYIjQAAFOEBgBgitAAAEwRGgCAqYDjOM5wXjAejysUCg3nJeFj2dnZXk9IWX19vdcTRhy//rTfzs5Orydck1gspqysrH5/nTsaAIApQgMAMEVoAACmCA0AwBShAQCYIjQAAFOEBgBgitAAAEwRGgCAKUIDADBFaAAApggNAMAUoQEAmCI0AABThAYAYIrQAABMERoAgClCAwAwdU2hiUQiCgQC2rhx4xDNAQCkm5RDc/ToUdXU1Gju3LlDuQcAkGZSCs2lS5e0atUqbd++XdnZ2UO9CQCQRlIKTUVFhZYvX65ly5Zd9dxEIqF4PN7nAACMHBluX1BXV6eWlhY1NzcP6vxIJKJXXnnF9TAAQHpwdUcTjUa1YcMG/fGPf9SYMWMG9ZqqqirFYrHkEY1GUxoKAPAnV3c0LS0t6ujoUGFhYfK5np4eHTlyRFu3blUikdCoUaP6vCYYDCoYDA7NWgCA77gKzdKlS3Xs2LE+z/34xz/WjBkz9Pzzz18RGQAAXIUmMzNTBQUFfZ4bO3asxo8ff8XzAABIfGcAAIAx1+86+7rDhw8PwQwAQLrijgYAYIrQAABMERoAgClCAwAwRWgAAKYIDQDAFKEBAJgiNAAAU4QGAGCK0AAATBEaAIApQgMAMEVoAACmCA0AwBShAQCYIjQAAFMBx3Gc4bxgPB5XKBQazksCnsjOzvZ6Qkq2bdvm9YSUtbW1eT0hJS+88ILXE65JLBZTVlZWv7/OHQ0AwBShAQCYIjQAAFOEBgBgitAAAEwRGgCAKUIDADBFaAAApggNAMAUoQEAmCI0AABThAYAYIrQAABMERoAgClCAwAwRWgAAKYIDQDAFKEBAJgiNAAAU65Cs2nTJgUCgT7H7bffbrUNAJAGMty+YPbs2WpoaEg+HjVq1JAOAgCkF9ehycjI4C4GADBorj9Hc/LkSeXl5Sk/P1+PP/642traBjw/kUgoHo/3OQAAI4er0Nx7773auXOnDh06pO3bt+vcuXNauHChLly40O9rIpGIQqFQ8giHw9c8GgDgH65CU1paqu9973uaM2eOli1bpr/85S+SpDfeeKPf11RVVSkWiyWPaDR6bYsBAL7i+nM0XzV27FjNmTNHJ0+e7PecYDCoYDB4LZcBAPjYNX0dTSKR0CeffKLc3Nyh2gMASDOuQvPcc8+psbFRp0+f1j/+8Q99//vfVzweV1lZmdU+AIDPufrQ2ZkzZ/TDH/5Q58+f14QJE/Ttb39bTU1NmjJlitU+AIDPuQpNXV2d1Q4AQJrie50BAEwRGgCAKUIDADBFaAAApggNAMAUoQEAmCI0AABThAYAYIrQAABMERoAgClCAwAwRWgAAKYIDQDAFKEBAJgiNAAAU4QGAGDK1Q8+g39t2bLF6wkpaWho8HpCyrKzs72ekJJly5Z5PSFle/bs8XoCvgF3NAAAU4QGAGCK0AAATBEaAIApQgMAMEVoAACmCA0AwBShAQCYIjQAAFOEBgBgitAAAEwRGgCAKUIDADBFaAAApggNAMAUoQEAmCI0AABThAYAYMp1aD7//HM98cQTGj9+vG6++WbdfffdamlpsdgGAEgDGW5O7uzs1KJFi/TAAw/owIEDysnJ0b///W/deuutRvMAAH7nKjS//vWvFQ6HVVtbm3xu6tSpQ70JAJBGXH3obP/+/SoqKtLKlSuVk5Oj+fPna/v27QO+JpFIKB6P9zkAACOHq9C0tbWpurpa06dP16FDh1ReXq5nnnlGO3fu7Pc1kUhEoVAoeYTD4WseDQDwD1eh6e3t1T333KPNmzdr/vz5Wrt2rX7605+qurq639dUVVUpFoslj2g0es2jAQD+4So0ubm5mjVrVp/nZs6cqfb29n5fEwwGlZWV1ecAAIwcrkKzaNEinThxos9zn376qaZMmTKkowAA6cNVaJ599lk1NTVp8+bNOnXqlHbt2qWamhpVVFRY7QMA+Jyr0CxYsEB79+7VW2+9pYKCAv3iF7/Qq6++qlWrVlntAwD4nKuvo5Gkhx9+WA8//LDFFgBAGuJ7nQEATBEaAIApQgMAMEVoAACmCA0AwBShAQCYIjQAAFOEBgBgitAAAEwRGgCAKUIDADBFaAAApggNAMAUoQEAmCI0AABThAYAYMr1Dz6DP3V2dno9ISXbtm3zesKIs2fPHq8npGzt2rVeT8A34I4GAGCK0AAATBEaAIApQgMAMEVoAACmCA0AwBShAQCYIjQAAFOEBgBgitAAAEwRGgCAKUIDADBFaAAApggNAMAUoQEAmCI0AABThAYAYIrQAABMERoAgClXoZk6daoCgcAVR0VFhdU+AIDPZbg5+ejRo+rp6Uk+/te//qWHHnpIK1euHPJhAID04Co0EyZM6PN4y5YtmjZtmu6///4hHQUASB+uQvNVly9f1ptvvqnKykoFAoF+z0skEkokEsnH8Xg81UsCAHwo5TcD7Nu3TxcvXtSTTz454HmRSEShUCh5hMPhVC8JAPChlEOzY8cOlZaWKi8vb8DzqqqqFIvFkkc0Gk31kgAAH0rpQ2efffaZGhoa9Pbbb1/13GAwqGAwmMplAABpIKU7mtraWuXk5Gj58uVDvQcAkGZch6a3t1e1tbUqKytTRkbK7yUAAIwQrkPT0NCg9vZ2rVmzxmIPACDNuL4lKSkpkeM4FlsAAGmI73UGADBFaAAApggNAMAUoQEAmCI0AABThAYAYIrQAABMERoAgClCAwAwRWgAAKYIDQDAFKEBAJgiNAAAU4QGAGCK0AAATA37j8jkZ9l4I5FIeD0hJV1dXV5PGHH++9//ej0BPnO1P9cDzjD/yX/mzBmFw+HhvCQAwFA0GtWkSZP6/fVhD01vb6+++OILZWZmKhAIDOk/Ox6PKxwOKxqNKisra0j/2Zb8ulvy73a/7pb8u92vuyX/brfe7TiOurq6lJeXpxtu6P8zMcP+obMbbrhhwPINhaysLF/9Zvgfv+6W/Lvdr7sl/273627Jv9std4dCoauew5sBAACmCA0AwFRahSYYDOrll19WMBj0eoorft0t+Xe7X3dL/t3u192Sf7dfL7uH/c0AAICRJa3uaAAA1x9CAwAwRWgAAKYIDQDAFKEBAJgiNAAAU4QGAGCK0AAATP0/2ENfMwIViVcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# preliminary data analysis\n",
    "print(\"the number of samples in the dataset is: \", X.shape[0])\n",
    "print(\"the dimension (or features) of each data sample is: \", X.shape[1])\n",
    "print(\"the mean value of the mean fetures values of the dataset is: {:.3f}\".format(np.mean(X)))\n",
    "print(\"the variance is: {:.3f}\".format(np.var(X)))\n",
    "print(\"the scaling of the data is: integers between 0 and 16\")\n",
    "print(\"heres an example of some data sample:\")\n",
    "plt.gray()\n",
    "plt.matshow(digits.images[3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <u>splitting the dataset and training</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "auoeX6Elzbbj"
   },
   "outputs": [],
   "source": [
    "# splitting the dataset, training it and eval\n",
    "def split_train_eval(X,y):\n",
    "    sc = StandardScaler()\n",
    "    sc.fit(X)\n",
    "    X = sc.transform(X)\n",
    "    for r in np.arange(0.1, 1.0, 0.1):\n",
    "      X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = r)\n",
    "      classifier = LogisticRegression(random_state = 0, max_iter=1000)\n",
    "      classifier.fit(X_train, y_train)  \n",
    "      y_pred = classifier.predict(X_test)\n",
    "      accuracy = accuracy_score(y_test, y_pred)  # Evaluate the misclassification\n",
    "      print(\"The accuracy of r = {:.1f} is: {:.3f}\".format(r, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of r = 0.1 is: 0.972\n",
      "The accuracy of r = 0.2 is: 0.972\n",
      "The accuracy of r = 0.3 is: 0.974\n",
      "The accuracy of r = 0.4 is: 0.962\n",
      "The accuracy of r = 0.5 is: 0.957\n",
      "The accuracy of r = 0.6 is: 0.953\n",
      "The accuracy of r = 0.7 is: 0.945\n",
      "The accuracy of r = 0.8 is: 0.943\n",
      "The accuracy of r = 0.9 is: 0.925\n"
     ]
    }
   ],
   "source": [
    "split_train_eval(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <u>creating an unbalanced dataset</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "udKn_nq651rA"
   },
   "outputs": [],
   "source": [
    "# define unbalanced dataset size\n",
    "num_per_class = [50, 50, 70, 60, 110, 120, 120, 120, 150, 150]\n",
    "assert np.sum(num_per_class) == 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty array to store the sampled data\n",
    "new_X = np.empty((0, X.shape[1]), dtype=X.dtype)\n",
    "new_y = np.empty((0,), dtype=y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from each class and append to the new dataset\n",
    "for i in range(10):\n",
    "    class_indices = np.where(y == i)[0]\n",
    "    # print(class_indices)\n",
    "    sampled_indices = np.random.choice(class_indices, size=num_per_class[i], replace=False)\n",
    "    new_X = np.concatenate((new_X, X[sampled_indices]), axis=0)\n",
    "    new_y = np.concatenate((new_y, y[sampled_indices]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the new dataset\n",
    "shuffle_indices = np.random.permutation(new_X.shape[0])\n",
    "new_X = new_X[shuffle_indices]\n",
    "new_y = new_y[shuffle_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the first 1000 examples from the shuffled dataset\n",
    "new_X = new_X[:1000]\n",
    "new_y = new_y[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <u>label balancing</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "2yH1Wl7U4ahP"
   },
   "outputs": [],
   "source": [
    "# balancing the labels\n",
    "lmin = np.min(np.bincount(new_y[:].astype(int)))\n",
    "\n",
    "balanced_X = np.empty((0, new_X.shape[1]), dtype=new_X.dtype)\n",
    "balanced_y = np.empty((0,), dtype=new_y.dtype)\n",
    "for label in range(len(set(new_y))):\n",
    "    partial_data_X = new_X[new_y == label, :]\n",
    "    partial_data_X = partial_data_X[np.random.choice(partial_data_X.shape[0], size=lmin, replace=False), :]\n",
    "    assert len(partial_data_X) == lmin\n",
    "    balanced_X = np.concatenate((balanced_X, partial_data_X), axis=0)\n",
    "    balanced_y = np.concatenate((balanced_y, np.full((lmin,), label)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of r = 0.1 is: 0.920\n",
      "The accuracy of r = 0.2 is: 0.960\n",
      "The accuracy of r = 0.3 is: 0.927\n",
      "The accuracy of r = 0.4 is: 0.940\n",
      "The accuracy of r = 0.5 is: 0.936\n",
      "The accuracy of r = 0.6 is: 0.917\n",
      "The accuracy of r = 0.7 is: 0.897\n",
      "The accuracy of r = 0.8 is: 0.877\n",
      "The accuracy of r = 0.9 is: 0.820\n"
     ]
    }
   ],
   "source": [
    "# splitting the dataset, training it and eval\n",
    "split_train_eval(balanced_X, balanced_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <u>naive k-features selection algorithm with k=2</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "AnNH2c9rBdgv"
   },
   "outputs": [],
   "source": [
    "# naive k-features selection algorithm with k=2\n",
    "def select_k_features(X_train, X_test, y_train, y_test, k):\n",
    "    n_features = X_train.shape[1]\n",
    "    feature_indices = list(range(n_features))\n",
    "    best_accuracy = 0.0\n",
    "    best_features = []\n",
    "    \n",
    "    # Generate all possible combinations of k features\n",
    "    feature_combinations = list(combinations(feature_indices, k))\n",
    "    \n",
    "    # For each combination of features, train a logistic regression classifier on the training set\n",
    "    # and evaluate its accuracy on the test set\n",
    "    for features in tqdm(feature_combinations):\n",
    "        lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "        lr.fit(X_train[:, features], y_train)\n",
    "        accuracy = lr.score(X_test[:, features], y_test)\n",
    "        \n",
    "        # If this set of features is the best so far, update the best_features and best_accuracy variables\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_features = features\n",
    "    \n",
    "    return best_features, best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2016/2016 [05:29<00:00,  6.11it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # Split data into train and test sets\n",
    "best_features, accuracy = select_k_features(X_train, X_test, y_train, y_test, k=2)  # Select the best 2 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best features: (21, 42)\n",
      "Accuracy: 47.22%\n"
     ]
    }
   ],
   "source": [
    "print(\"Best features:\", best_features)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMLYNk3uar9KjEQUqOWGWI/",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
